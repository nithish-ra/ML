# ğŸ’° Loan Sanction Amount Prediction

This machine learning project predicts loan sanction amounts based on customer and property details. It uses:
- ğŸ”¹ **Linear Regression** for baseline comparison
- ğŸ”¹ **Support Vector Regression (SVR)** with hyperparameter tuning

> ğŸ“Š Dataset used: [Predict Loan Amount Dataset](https://www.kaggle.com/datasets/phileinsophos/predict-loan-amount-data) from Kaggle

---

## ğŸ§¾ Project Goals

- Understand relationships between features and sanctioned loan amounts.
- Handle missing values, outliers, and categorical encoding.
- Perform feature selection using Random Forest.
- Train and compare two regression models:
  - Linear Regression
  - SVR with RBF, Polynomial, and Linear kernels (tuned via GridSearchCV)

---

## ğŸ“¦ Tech Stack

- `Python 3`
- `pandas`, `numpy`
- `seaborn`, `matplotlib`
- `scikit-learn` (regression models, scaling, CV, GridSearch)

---

## ğŸ“Š Workflow

### 1. **Data Preprocessing**
- Dropped irrelevant columns (`Customer ID`, `Name`, etc.)
- Handled missing values:
  - Numeric â†’ Median
  - Categorical â†’ Mode
- Encoded categoricals using `LabelEncoder`
- Clipped outliers (1stâ€“99th percentile)
- Feature scaling via `StandardScaler`

### 2. **Exploratory Data Analysis**
- Boxplots for outliers
- Correlation heatmaps
- Distribution plots
- Scatter plots for target vs top features

### 3. **Feature Selection**
- Used `RandomForestRegressor` to rank features
- Top 10 features were selected for modeling

### 4. **Modeling**

#### ğŸ”¹ Linear Regression
- Evaluated using:
  - RÂ² and Adjusted RÂ²
  - MAE, MSE, RMSE
  - 5-Fold Cross-Validation
- Visualized: Actual vs Predicted scatter plots

#### ğŸ”¹ Support Vector Regression (SVR)
- Pipeline with scaling + SVR
- GridSearchCV over:
  - Kernels: `rbf`, `poly`, `linear`
  - `C`, `epsilon`, `gamma`, `degree`
- Evaluated on:
  - Validation set
  - Cross-validation (RÂ²)
  - Test set performance
- Visualized predictions

---

## ğŸ” Model Comparison

| Metric         | Linear Regression | SVR (Best Kernel) |
|----------------|------------------:|------------------:|
| Validation RÂ²  | ~0.57             | ~0.16             |
| CV RÂ² (mean)   | ~0.55             | ~0.09             |
| Test RÂ²        | ~0.55             | ~0.15             |

> âœ… **Linear Regression** performed better than SVR in this experiment.

---

## ğŸ“ˆ Visualizations
- ğŸ“¦ Boxplots (before/after outlier treatment)
- ğŸ”¥ Correlation heatmap
- ğŸ” Predicted vs Actual scatter plots
- ğŸ§  Feature importance bar chart

---


## ğŸ“Š Results Summary - LR

The model's performance was evaluated on the validation set, yielding the following key metrics:

* **Mean Absolute Error (MAE):** 21,479.00
* **Root Mean Squared Error (RMSE):** 30,346.77
* **RÂ² Score:** 0.5744
* **Adjusted RÂ² Score:** 0.5737

The cross-validation results confirmed this performance, with an average RÂ² score of **0.57**, indicating that the model generalizes well to unseen data.



